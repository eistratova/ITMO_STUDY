{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9QLe_T6GZUd"
      },
      "source": [
        "# Задание на программирование"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYlIf2yHv8hz"
      },
      "source": [
        "**Выполнять задание следует с текущими значениями гиперпараметров. Для проверки ниже будут приведены ответы, которые должны получиться в результате выполнения задания. После того, как все ответы совпадут, можно будет использовать полученный блокнот для выполнения индивидуального задания.** Изменены параметры - изначально  random_seed = 100 Остальные параметры без изменения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDQzNIZXAoFE"
      },
      "source": [
        "Зададим гиперпараметры модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NOMw2ZbOAmOZ"
      },
      "outputs": [],
      "source": [
        "epsilon = 0.1 # Параметр эпсилон при использовании эпсилон жадной стратегии\n",
        "gamma = 0.8 # Коэффциент дисконтирования гамма\n",
        "random_seed = 6 #Random seed\n",
        "time_delay = 1 # Задержка времени при отрисовке процесса игры после обучения (секунды)\n",
        "lr_rate = 0.9 #Коэффициент скорости обучения альфа"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQu5IYHX8jId"
      },
      "source": [
        "Импортируем библиотеки, создаем свою среду размера 6х6. S обозначает точку старта. F -- лед безопасен, H -- проталина, G -- цель. Параметр `is_slippery=False` отвечает за условное отсутствие скольжения. То есть если агент выбрал действие пойти направо, то он переместится в соответствующее состояние. В общем случае из-за \"скольжения\" можно оказаться в другом состоянии. Мы также скопировали из библиотки GYM и слегка модифицировали функцию ```generate_random_map ```, для того, чтобы генерировать произвольные карты на основе ```random_seed ```.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "awL7CCCwD6C3",
        "outputId": "5b2d42db-dc19-4cef-f753-805b8b6be9c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ваша карта\n",
            "\n",
            "\u001b[41mS\u001b[0mFHFFF\n",
            "FFFFFF\n",
            "FFFHHF\n",
            "HHFFHF\n",
            "FFFHFF\n",
            "FHFFFG\n"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade gym==0.18.0\n",
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "def generate_random_map(size, p, sd):\n",
        "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
        "    :param size: size of each side of the grid\n",
        "    :param p: probability that a tile is frozen\n",
        "    \"\"\"\n",
        "    valid = False\n",
        "    np.random.seed(sd)\n",
        "\n",
        "    # DFS to check that it's a valid path.\n",
        "    def is_valid(res):\n",
        "        frontier, discovered = [], set()\n",
        "        frontier.append((0,0))\n",
        "        while frontier:\n",
        "            r, c = frontier.pop()\n",
        "            if not (r,c) in discovered:\n",
        "                discovered.add((r,c))\n",
        "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
        "                for x, y in directions:\n",
        "                    r_new = r + x\n",
        "                    c_new = c + y\n",
        "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
        "                        continue\n",
        "                    if res[r_new][c_new] == 'G':\n",
        "                        return True\n",
        "                    if (res[r_new][c_new] not in '#H'):\n",
        "                        frontier.append((r_new, c_new))\n",
        "        return False\n",
        "\n",
        "    while not valid:\n",
        "        p = min(1, p)\n",
        "        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1-p])\n",
        "        res[0][0] = 'S'\n",
        "        res[-1][-1] = 'G'\n",
        "        valid = is_valid(res)\n",
        "    return [\"\".join(x) for x in res]\n",
        "\n",
        "#Генерация карты\n",
        "random_map = generate_random_map(size=6, p=0.8, sd = random_seed) #Создаем свою карту\n",
        "env = gym.make(\"FrozenLake-v0\", desc=random_map, is_slippery=False) #Инициализируем среду\n",
        "print(\"Ваша карта\")\n",
        "env.render() #Выводим карту на экран"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDCexoEU9a_c"
      },
      "source": [
        "Функции выбора действия и обновления таблицы ценности действий. Строчка *** используется для того, чтобы проверять ответы в openedx. Вне рамках академической задачи лучше использовать оригинальный метод класса `environment`, то есть:\n",
        "\n",
        "`action = env.action_space.sample()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5TbDqn6G_Pt"
      },
      "source": [
        "# Задача 1\n",
        "Дополните функцию ```learn()```, чтобы в результате ее вызова обновлялось значение ценности текущего действия согласно алгоритму Q-обучения\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CdQBpxaTOK7u"
      },
      "outputs": [],
      "source": [
        "def choose_action(state):\n",
        "    action=0\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        action = np.random.randint(0,env.action_space.n) #***\n",
        "    else:\n",
        "        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
        "    return action\n",
        "\n",
        "def learn(state, state2, reward, action, done):\n",
        "    #Q-learning\n",
        "    if done:\n",
        "      Q[state, action] = Q[state, action] + lr_rate * (reward - Q[state, action])\n",
        "    else:\n",
        "      Q[state, action] = Q[state, action] + lr_rate * (reward + gamma * np.max(Q[state2, :]) - Q[state, action])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7COGeyA_Ist3"
      },
      "source": [
        "# Задача 2\n",
        "Дополните следующий код так, чтобы в результате обучения модели можно было узнать количество побед и номер игры (`game`), на котором агент впервые одержал пятую победу подряд."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0adDl7NvJoQP"
      },
      "source": [
        "Поясним, что возвращает функция ```env.step(action)```\n",
        "\n",
        "```state2``` -- следующее состояние\n",
        "\n",
        "```reward``` -- награда\n",
        "\n",
        "```done``` -- флаг окончания игры. True в случае победы или падения в проталину. False в остальных случаях.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "aq92-dWiOchF",
        "outputId": "91ec4dc4-fb39-4818-ac78-79c9fe6d0ee7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:16<00:00, 598.17it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "# Inititalization\n",
        "wins_arr = [] \n",
        "np.random.seed(random_seed)\n",
        "total_episodes = 10000\n",
        "max_steps = 100\n",
        "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "min_episode = 0 #delete\n",
        "#Main cycle\n",
        "for episode in tqdm(range(total_episodes)):\n",
        "    state = env.reset()\n",
        "    t = 0\n",
        "    while t < max_steps:\n",
        "        \n",
        "        if episode > 5 and wins_arr[episode-5] == 1 and wins_arr[episode-4] == 1 and wins_arr[episode-3] == 1 and wins_arr[episode-2] == 1 and wins_arr[episode-1] == 1 and min_episode ==0:\n",
        "          min_episode = episode\n",
        "        \n",
        "    \n",
        "        t += 1\n",
        "\n",
        "        action = choose_action(state)\n",
        "\n",
        "        state2, reward, done, info = env.step(action)\n",
        "\n",
        "        if t == max_steps:\n",
        "          done = True  \n",
        "\n",
        "        learn(state, state2, reward, action, done)\n",
        "\n",
        "        state = state2\n",
        "\n",
        "        if done and reward == 1:\n",
        "          wins_arr.append(1) #record if won\n",
        "          break\n",
        "\n",
        "        if done:\n",
        "          wins_arr.append(0) #record if lost\n",
        "          break\n",
        "\n",
        "#print(\"Таблица ценностей действий\")\n",
        "#print(np.round(Q,2))\n",
        "#Number of wins\n",
        "      \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFuxsqdRLOS9"
      },
      "source": [
        "Вывод ответов при заданных параметрах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xZbJtFnhLa7w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество побед в серии из 10 000 игр:  2202\n",
            "Пять побед подряд впервые было одержано в игре  7473\n"
          ]
        }
      ],
      "source": [
        "print(\"Количество побед в серии из 10 000 игр: \", np.sum(wins_arr))\n",
        "print(\"Пять побед подряд впервые было одержано в игре \", min_episode)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSXdSiG2WI71"
      },
      "source": [
        "Должны получиться следующие результаты.\n",
        "\n",
        "\n",
        "*  Количество побед в серии из 10 000 игр:  7914\n",
        "*  Пять побед подряд впервые было одержано в игре  885\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nazZaAbwQGBt"
      },
      "source": [
        "Произведем одну игру, чтобы проследить за действиями агента. При этом будем считать модель полностью обученной, то есть действия выбираются жадно, значения ценностей действий в таблице не обновляются."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "5ysllZjEQXLa",
        "outputId": "29ec2e79-a0d5-4fcb-a551-6209d40dd7ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "!!!Победа!!!\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "#Жадный выбор действий\n",
        "def choose_action_one_game(state):\n",
        "    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
        "    return action\n",
        "\n",
        "states=[]#Массив для сохранения состояний агента в течение игры\n",
        "t = 0\n",
        "state = env.reset()\n",
        "wn = 0\n",
        "while(t<100):\n",
        "  env.render()\n",
        "  time.sleep(time_delay)\n",
        "  clear_output(wait=True)\n",
        "  action = choose_action_one_game(state)  \n",
        "  state2, reward, done, info = env.step(action)  \n",
        "  states.append(state)\n",
        "  state = state2\n",
        "  t += 1\n",
        "  if done and reward == 1:\n",
        "    wn=1\n",
        "  if done:\n",
        "    break\n",
        "if wn == 1:\n",
        "  print(\"!!!Победа!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x696NulpReFI"
      },
      "source": [
        "Отобразим маршрут"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "UKMCMdpOTcXy",
        "outputId": "bd9a32aa-b615-407f-bb4b-9a2ae654df4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ffc88895340>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_maze_pic(maze):\n",
        "  maze_pic=[]\n",
        "  for i in range(len(maze)):\n",
        "    row = []\n",
        "    for j in range(len(maze[i])):\n",
        "      if maze[i][j] == 'S':\n",
        "        row.append(0)\n",
        "      if maze[i][j] == 'F':\n",
        "        row.append(0)\n",
        "      if maze[i][j] == 'H':\n",
        "        row.append(1)\n",
        "      if maze[i][j] == 'G':\n",
        "        row.append(0)\n",
        "    maze_pic.append(row)\n",
        "  maze_pic = np.array(maze_pic)\n",
        "  return maze_pic\n",
        "  \n",
        "\n",
        "#Make maze fit to plot\n",
        "maze_pic = make_maze_pic(random_map)\n",
        "nrows, ncols = maze_pic.shape\n",
        "\n",
        "#Arrays of picture elements\n",
        "rw = np.remainder(states,nrows)\n",
        "cl = np.floor_divide(states,nrows)\n",
        "if wn == 1:\n",
        "  rw = np.append(rw, [nrows-1])\n",
        "  cl = np.append(cl,[ncols-1])\n",
        "\n",
        "#Picture plotting\n",
        "fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n",
        "ax1.clear()\n",
        "ax1.set_xticks(np.arange(0.5, nrows, step=1))\n",
        "ax1.set_xticklabels([])\n",
        "ax1.set_yticks(np.arange(0.5, ncols, step=1))\n",
        "ax1.set_yticklabels([])\n",
        "ax1.grid(True)\n",
        "ax1.plot([0],[0], \"gs\", markersize=40)  # start is a big green square\n",
        "ax1.text(0, 0.2,\"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Start text\n",
        "ax1.plot([nrows-1],[ncols-1], \"rs\", markersize=40)  # exit is a big red square\n",
        "ax1.text(nrows-1, ncols-1+0.2,\"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Exit text\n",
        "ax1.plot(rw,cl, ls = '-', color = 'blue') #Blue lines path\n",
        "ax1.plot(rw,cl, \"bo\")  # Blue dots visited cells\n",
        "ax1.imshow(maze_pic, cmap=\"binary\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
