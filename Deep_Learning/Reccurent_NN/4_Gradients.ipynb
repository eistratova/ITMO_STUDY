{"cells":[{"cell_type":"markdown","id":"7c83cdce-023b-4d89-aed6-dcd04f634a8f","metadata":{"pycharm":{"name":"#%% md\n"},"id":"7c83cdce-023b-4d89-aed6-dcd04f634a8f"},"source":["# Взрывающиеся и исчезающие градиенты\n","\n","В данном ноутбуке мы расскажем про то, какими проблемами обладают градиенты при обучении нейронных сетей, когда их можно встретить и как избежать."]},{"cell_type":"code","execution_count":null,"id":"f8a649b4-5734-4087-8226-291190ad2d5e","metadata":{"pycharm":{"name":"#%%\n"},"id":"f8a649b4-5734-4087-8226-291190ad2d5e","outputId":"9d3f210b-b1d4-4fda-8090-efe74817e61c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (2.5.0)\n","Requirement already satisfied: tensorboard~=2.5 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: wheel>=0.35 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (0.35.1)\n","Requirement already satisfied: keras>=2.4.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (2.6.0)\n","Requirement already satisfied: google-pasta~=0.2 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.1.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (3.2.1)\n","Requirement already satisfied: six>=1.15.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: flatbuffers~=1.12 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (1.12)\n","Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (3.14.0)\n","Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (3.7.4.3)\n","Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: wrapt>=1.11.2 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: keras-preprocessing>=1.1.2 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: numpy>=1.19 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (1.20.1)\n","Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (1.34.1)\n","Requirement already satisfied: gast==0.4.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: absl-py~=0.10 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (0.12.0)\n","Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.21.3)\n","Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.6.0)\n","Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (52.0.0.post20210125)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.25.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.6)\n","Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kell\\.conda\\envs\\ds\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n"]}],"source":["!pip install tensorflow\n","\n","import tensorflow as tf"]},{"cell_type":"markdown","id":"332fc233-9561-4981-8f39-4155b4423384","metadata":{"tags":[],"pycharm":{"name":"#%% md\n"},"id":"332fc233-9561-4981-8f39-4155b4423384"},"source":["## Взрыв градиентов (exploding gradients, gradient burst)\n","\n","### Что это?\n","\n","Взрыв градиентов - это ситуация, когда на начальном этапе обучения вследствие достаточно больших ошибок сети градиенты накапливаются в достаточно значительном масштабе и при обратном распространении ошибки значения весов очень сильно изменяются. Вследствие стохастической природы алгоритма оптимизации, это может привести к тому, что сеть попадет в состояние с еще большей ошибкой (на другом краю ямы минимума в многомерном пространстве оптимизации) и последующий градиент будет еще большим. Сеть попадает в самразбалансирующийся процесс накопления градиентов, и они вскоре достигают огромных размеров. Обычно это выражается в нестабильном обучении (если взрыв градиентов проходит) или вообще в невозможности обучить сеть.  \n","\n","### Где можно встретить взрыв градиентов?\n","Чаще всего взрыв градиентов можно встретить вследствие ошибок в реализации модулей, градиентного спуска или функции потерь, если вы используете нестандартные модули или разрабатываете самостоятельно. Работая с стандартными модулями и средствами создания нейронных сетей, чаще всего взрыв градиентов встречается при работе с рекуррентными сетями и генеративными состязательными сетями.\n","\n","### Как понять, что происходит взрыв градиентов?\n","- Значение функции потерь очень быстро растет\n","- Значение функции потерь стало равно NaN\n","- Веса слоев приобрели очень большие значения\n","\n","### Как предотвратить взрыв градиентов?\n","В первую очередь, в случае использования нестандартных модулей, стоит проверить их реализацию с использованием отладчика. В случае же использования стандартных модулей можно:\n","- В случае обучения рекуррентных моделей использовать LSTM или GRU слои вместо простых рекуррентных слоев\n","- Уменьшить размер батча, снизив т.о. величину градиента на каждом шаге\n","- Использовать gradient clipping (см. ниже)\n","- Использовать регуляризацию весов в слое (см. ниже)\n","- Уменьшить значение learning rate"]},{"cell_type":"markdown","id":"0de317f8-d69a-4b03-84c9-4fc2277e17d4","metadata":{"pycharm":{"name":"#%% md\n"},"id":"0de317f8-d69a-4b03-84c9-4fc2277e17d4"},"source":["Регуляризация слоев возможна с помощью модуля `tf.keras,regularizers`. В нем содержатся стандартные имплементации знакомых вам L1 и L2 регуляризационных техник, которые можно использовать для слоев нейронной сети.\n","\n","Также в модуле `tensorflow.keras.constraints` доступны ограничения на веса. С помощью данных техник можно поставить ограничения на веса слоя (по максимальному значению веса нейрона, запретить отрицательные значения, и т.д."]},{"cell_type":"code","execution_count":null,"id":"dc3a875b-aae4-4a6e-8ccd-be45302dfb8c","metadata":{"pycharm":{"name":"#%%\n"},"id":"dc3a875b-aae4-4a6e-8ccd-be45302dfb8c"},"outputs":[],"source":["from tensorflow.keras.regularizers import l1, l2, l1_l2\n","from tensorflow.keras.constraints import MaxNorm\n","\n","layer = tf.keras.layers.Dense(\n","    32,\n","    kernel_regularizer=l1(0.01),\n","    bias_regularizer=l2(0.02),\n","    activity_regularizer=l1_l2(0.01),\n","    \n","    kernel_constraint=MaxNorm(2),\n","    bias_constraint=MaxNorm(2)\n",")"]},{"cell_type":"markdown","id":"f0515f5f-7fce-4476-856d-63d814ba4540","metadata":{"pycharm":{"name":"#%% md\n"},"id":"f0515f5f-7fce-4476-856d-63d814ba4540"},"source":["Gradient Clipping - это техника ограничения максимального значения градиента. Все значения больше, чем максимальное, уменьшаются до максимального.\n","Ограничение градиента реализуется в любом оптимизаторе с помощью параметра clipvalue (ограничение максимального значения) или clipnorm (ограничение нормы)."]},{"cell_type":"code","execution_count":null,"id":"1cfe05e5-4730-4498-809d-b35477807935","metadata":{"pycharm":{"name":"#%%\n"},"id":"1cfe05e5-4730-4498-809d-b35477807935"},"outputs":[],"source":["from tensorflow.keras.optimizers import Adam\n","\n","opt = Adam(\n","    learning_rate=0.01,\n","    clipnorm=1.0,\n","    clipvalue=3.0\n",")"]},{"cell_type":"markdown","id":"6acbdd72-b9d4-4cfb-9d6b-042541f2ebfe","metadata":{"pycharm":{"name":"#%% md\n"},"id":"6acbdd72-b9d4-4cfb-9d6b-042541f2ebfe"},"source":["---"]},{"cell_type":"markdown","id":"276ce582-cdee-4340-be46-77ad9804215c","metadata":{"pycharm":{"name":"#%% md\n"},"id":"276ce582-cdee-4340-be46-77ad9804215c"},"source":["## Затухание градиента\n","\n","### Что такое затухание градиента?\n","Затухание градиента - гораздо более частая проблема, которую можно встретить при обучении нейронных сетей. Чаще всего это проблема касается не всей сети в целом, а отдельных ее частей. Суть затухания градиента заключается в том, что по разным причинам градиент на текущем участке становится настолько мал, что лишь незначительно изменяет веса на данном участке. Это может происходить по разным причинам, но обычно результатом этого является очень медленный (или остановившийся совсем) процесс обучения нейронной сети."]},{"cell_type":"markdown","id":"00829e9c-786a-421c-b107-d069e533032d","metadata":{"pycharm":{"name":"#%% md\n"},"id":"00829e9c-786a-421c-b107-d069e533032d"},"source":["### Почему происходит затухание градиента?\n","Есть множество разных причин, по которым градиент может затухать.\n","#### Функции активации\n","Некоторые функции активации (такие, как tanh или sigmoid) ограничивают значение в отрезке около 0 ($[-1; +1]$ и $[0; 1]$ соответственно). При использовании нескольких слоев, каждый последующий слой в процессе обратного распространения ошибки (т.е. более близкий к началу сети) будет получать все меньшие значения градиентов, т.о. слои ближе к началу будут медленнее обновлять свои веса в процессе оптимизации.\n","#### Глубина сети\n","При использовании очень глубоких сетей градиент может затухать вне зависимости от выбора функции активации, т.к. его абсолютное значение уменьшается в процессе обратного распространения.\n","#### Использование рекуррентных сетей\n","В рекуррентных сетях вследствие необходимости подсчета градиента по всей цепочке данных в обратную сторону, проблема затухающих градиентов также встречается достаточно часто."]},{"cell_type":"markdown","id":"28bf56eb-02d5-4146-b2a9-ca3f0c169b6b","metadata":{"pycharm":{"name":"#%% md\n"},"id":"28bf56eb-02d5-4146-b2a9-ca3f0c169b6b"},"source":["### Как предотвратить затухание градиента?\n","- Используйте альтернативные функции активации. Такие функции, как ReLU, LeakyReLU слабее ограничивают значение градиента и способствуют более легкому его распространению\n","    - В общем случае рекомендуется использовать LeakyReLU вместо ReLU, т.к. последний обладает неприятным свойством обнуления нейрона. Т.к. производная данной функции активации равна 0 при отрицательном значении нейрона, если нейрон будет выдавать отрицательные значения, то его процесс обучения остановится и градиенты больше не будут его обновлять. Данный нейрон будет \"мертвым\" и т.о. емкость вашей сети снижается.\n","- Используйте архитектуры сетей, в которых присутствуют skip connections. Такие соединения позволяют градиенту более свободно проходить до начальных слоев. Изобретение сети ResNet, в которой данный подход был представлен, позволило обучать гораздо более глубокие сети, нежели до этого. Некоторые современные исследования (см. https://habr.com/ru/post/351924/) показывают, что кажется, что нет причин вообще _**не**_ использовать skip connections в нейронных сетях.\n","- В случае использования рекуррентных сетей используйте модули LSTM и GRU, которые позволяют градиенту более свободно течь в процессе обучения, нежели стандартные рекуррентные слои."]}],"metadata":{"kernelspec":{"display_name":"ds","language":"python","name":"ds"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}