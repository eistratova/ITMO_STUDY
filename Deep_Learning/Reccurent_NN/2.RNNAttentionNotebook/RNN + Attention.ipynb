{"cells":[{"cell_type":"markdown","id":"61d455d9-3fa9-423a-8528-8248ab03ddd5","metadata":{"pycharm":{"name":"#%% md\n"},"id":"61d455d9-3fa9-423a-8528-8248ab03ddd5"},"source":["В этом ноутбуке мы с вами попробуем применить рекуррентные сети к задаче классификации текста, а также реализовать модуль внимания и имплементировать сеть вместе с ним.\n","\n","Как обычно, сначала убедимся, что у нас установлены все необходимые пакеты."]},{"cell_type":"code","execution_count":null,"id":"7e94aa74-49ff-4506-962b-06e2da59e7d8","metadata":{"pycharm":{"name":"#%%\n"},"id":"7e94aa74-49ff-4506-962b-06e2da59e7d8","outputId":"3c664e85-b5a6-4fcd-deda-8ffe2dad41de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pandas in /Users/bojcevanton/miniconda3/envs/ipynb_installation/lib/python3.8/site-packages (1.4.2)\r\n","\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\u001b[0m\r\n","\u001b[31mERROR: No matching distribution found for tensorflow\u001b[0m\r\n"]}],"source":["!pip install pandas tensorflow "]},{"cell_type":"markdown","id":"725f0331-d6a4-4bd3-ae19-e96e6449fc32","metadata":{"pycharm":{"name":"#%% md\n"},"id":"725f0331-d6a4-4bd3-ae19-e96e6449fc32"},"source":["Далее импортируем необходимые слои, включая технические Layer и backend - K. Данные классы нам будут необходимы для дальнейшей реализации модули внимания."]},{"cell_type":"code","execution_count":null,"id":"7871de07-5c0d-4072-9107-68f5cdb29255","metadata":{"pycharm":{"name":"#%%\n"},"id":"7871de07-5c0d-4072-9107-68f5cdb29255"},"outputs":[],"source":["import pandas as pd\n","import tensorflow as tf\n","\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, Layer, Input\n","\n","from tensorflow.keras import backend as K"]},{"cell_type":"markdown","id":"676dac39-a7b2-4b6d-8928-a4bacfb9f8f1","metadata":{"pycharm":{"name":"#%% md\n"},"id":"676dac39-a7b2-4b6d-8928-a4bacfb9f8f1"},"source":["В качестве набора данных возьмем обработанный набор \"Depression and Anxiety in Twitter (ID)\" [(оригинал)](https://www.kaggle.com/stevenhans/depression-and-anxiety-in-twitter-id). Это набор твитов на индонезийском языке, часть из которых содержат депрессивные или тревожные мысли. В каждой строке данного набора два объекта - текст твита на индонезийском языке и бинарная метка наличия депрессивных мыслей в тексте. Таким образом, входными данными будет текст на естественном языке, решаемая задача - бинарная классификация."]},{"cell_type":"code","execution_count":null,"id":"7fc6e607-a5b0-4b81-9ed8-326960365b73","metadata":{"pycharm":{"name":"#%%\n"},"id":"7fc6e607-a5b0-4b81-9ed8-326960365b73","outputId":"21882027-3811-40cf-ac76-8090df1eb175"},"outputs":[{"data":{"text/plain":"                                                text  label\n0  oh pantesan tadi pada rame, ternyata monek mau...      0\n1       Semakin bertambah usia, semakin cemas hidup.      0\n2                                 gelisah bgt astaga      1\n3  Udah jangan terlalu cemas sikapku tak berubah ...      0\n4  Giliran Aldebaran diambang kematian...Semua ba...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>oh pantesan tadi pada rame, ternyata monek mau...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Semakin bertambah usia, semakin cemas hidup.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>gelisah bgt astaga</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Udah jangan terlalu cemas sikapku tak berubah ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Giliran Aldebaran diambang kematian...Semua ba...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["train = pd.read_csv('datd_train.csv')\n","test = pd.read_csv('datd_test.csv')\n","train.head()"]},{"cell_type":"markdown","id":"d96bbb34-6c18-4f35-b64b-cc9f72957021","metadata":{"pycharm":{"name":"#%% md\n"},"id":"d96bbb34-6c18-4f35-b64b-cc9f72957021"},"source":["Разделим тренировочный и тестовые наборы на текст и разметку."]},{"cell_type":"code","execution_count":null,"id":"874dd91e-6c04-4d82-bce2-0804f89db866","metadata":{"pycharm":{"name":"#%%\n"},"id":"874dd91e-6c04-4d82-bce2-0804f89db866","outputId":"096cb127-723a-4e70-accb-20b3b95cc88a"},"outputs":[{"name":"stdout","output_type":"stream","text":["oh pantesan tadi pada rame, ternyata monek mau cb juni. cemas aku tuh  --  0\n"]}],"source":["X_train = train['text']\n","y_train = train['label'].tolist()\n","\n","X_test = test['label']\n","y_test = test['label'].tolist()\n","\n","print(X_train[0], \" -- \", y_train[0])"]},{"cell_type":"markdown","id":"a358d1f4-560b-4cee-abbe-efa8e9f48226","metadata":{"pycharm":{"name":"#%% md\n"},"id":"a358d1f4-560b-4cee-abbe-efa8e9f48226"},"source":["Для использования текста в качестве тренировочных данных его необходимо предобработать. В данном случае мы проведем векторизацию текста - соотнесем каждое слово с определенным вектором фиксированного размера. Используя заранее известный размер словаря, создадим модуль векторизации и предварительно натренируем его на входном тексте."]},{"cell_type":"code","execution_count":null,"outputs":[{"data":{"text/plain":"(2201,)"},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"oyfrqcP63XSj","outputId":"a9f8f36c-b3b9-44cc-844f-7a1a550b2e78"},"id":"oyfrqcP63XSj"},{"cell_type":"code","execution_count":null,"id":"46d07f41-819c-4adf-9dc2-6f8889255f0d","metadata":{"pycharm":{"name":"#%%\n"},"id":"46d07f41-819c-4adf-9dc2-6f8889255f0d","outputId":"601be7c9-b8ff-409d-c5ba-6612d80df412"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-09-23 17:15:20.545154: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]}],"source":["VOCAB_SIZE = 4000\n","\n","encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=VOCAB_SIZE)\n","encoder.adapt(X_train)"]},{"cell_type":"markdown","id":"74ad84a5-2681-4bcb-8bd4-e131753354d5","metadata":{"pycharm":{"name":"#%% md\n"},"id":"74ad84a5-2681-4bcb-8bd4-e131753354d5"},"source":["Далее создадим модель для классификации. Для обработки слоя сразу после энкодера, занимающегося векторизацией текста, добавим Embedding слой - данный слой будет получать на вход числовое представление текста после векторизации и преобразовывать в плотный вектор вещественных чисел. Это позволит сократить длину вектора и перейти от целочисленного представления (после векторизатора) к вещественному.  \n","\n","Следующими идут два LSTM слоя, обернутых в директиву Bidirectional. Данная директива позволит слоям обработать текст дважды - слева-направо и справа-налево, позволяя учитывать контекст для каждого слова с обеих сторон. Первый слой из этих двух инициализирован параметром `return_sequences`, что позволит следующему слову получить все скрытые состояние предыдущего, а не только последнее. В итоге выходной вектор будет трехмерным: $[batch, timestep, data]$. Второй слой инициализирован без данного параметра, т.к. выходом для последующего полносвязного слоя должен служить двумерный вектор $[batch, data]$."]},{"cell_type":"code","execution_count":null,"id":"8d1ee68c-ff27-43f5-aa50-4f3928f9d518","metadata":{"pycharm":{"name":"#%%\n"},"id":"8d1ee68c-ff27-43f5-aa50-4f3928f9d518"},"outputs":[],"source":["model_bilstm = tf.keras.Sequential([\n","    Input(shape=(1,), dtype=tf.string),\n","    encoder,\n","    Embedding(input_dim=len(encoder.get_vocabulary()), output_dim=100),\n","    Bidirectional(LSTM(32, return_sequences=True)),\n","    Bidirectional(LSTM(32)),\n","    Dense(32, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])"]},{"cell_type":"markdown","id":"2e9c5932-0c85-46aa-9add-076877468148","metadata":{"pycharm":{"name":"#%% md\n"},"id":"2e9c5932-0c85-46aa-9add-076877468148"},"source":["Т.к. это задача бинарной классификации, скомпилируем модель с бинарной кроссэнтропией в качестве функции потерь и метрикой точности."]},{"cell_type":"code","execution_count":null,"id":"0b43f951-0551-40e2-9f78-5b01aa98d6b4","metadata":{"pycharm":{"name":"#%%\n"},"id":"0b43f951-0551-40e2-9f78-5b01aa98d6b4"},"outputs":[],"source":["model_bilstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"markdown","id":"86e3735d-8ed4-4422-9018-58a6ccdb4895","metadata":{"pycharm":{"name":"#%% md\n"},"id":"86e3735d-8ed4-4422-9018-58a6ccdb4895"},"source":["Запустим процесс обучения. Заметим, каких значений достигла точность и функция потерь на валидационной выборке."]},{"cell_type":"code","execution_count":null,"id":"87b4e111-a41d-4ca2-a025-80cc3546c1bb","metadata":{"tags":[],"pycharm":{"name":"#%%\n"},"id":"87b4e111-a41d-4ca2-a025-80cc3546c1bb","outputId":"caf40594-5256-49de-94db-f5dbf5059d7c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["2022-09-23 17:15:23.563519: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:15:23.941789: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:15:23.957201: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:15:24.110669: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:15:24.121986: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:15:24.300808: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:15:24.319074: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:15:24.519018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:15:24.539605: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["18/18 [==============================] - ETA: 0s - loss: 0.6504 - accuracy: 0.6533"]},{"name":"stderr","output_type":"stream","text":["2022-09-23 17:15:31.165715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:15:31.299139: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:15:31.306596: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:15:31.427983: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:15:31.436094: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["18/18 [==============================] - 11s 438ms/step - loss: 0.6504 - accuracy: 0.6533 - val_loss: 0.5720 - val_accuracy: 0.7073\n","Epoch 2/10\n","18/18 [==============================] - 3s 192ms/step - loss: 0.5589 - accuracy: 0.7083 - val_loss: 0.4701 - val_accuracy: 0.7818\n","Epoch 3/10\n","18/18 [==============================] - 2s 132ms/step - loss: 0.4322 - accuracy: 0.8192 - val_loss: 0.4216 - val_accuracy: 0.8109\n","Epoch 4/10\n","18/18 [==============================] - 2s 122ms/step - loss: 0.3086 - accuracy: 0.8869 - val_loss: 0.4284 - val_accuracy: 0.8091\n","Epoch 5/10\n","18/18 [==============================] - 2s 124ms/step - loss: 0.2229 - accuracy: 0.9269 - val_loss: 0.5348 - val_accuracy: 0.7927\n","Epoch 6/10\n","18/18 [==============================] - 2s 119ms/step - loss: 0.1766 - accuracy: 0.9446 - val_loss: 0.5287 - val_accuracy: 0.7873\n","Epoch 7/10\n","18/18 [==============================] - 2s 116ms/step - loss: 0.1582 - accuracy: 0.9487 - val_loss: 0.5977 - val_accuracy: 0.8000\n","Epoch 8/10\n","18/18 [==============================] - 2s 118ms/step - loss: 0.1261 - accuracy: 0.9618 - val_loss: 0.6289 - val_accuracy: 0.7818\n","Epoch 9/10\n","18/18 [==============================] - 2s 118ms/step - loss: 0.1308 - accuracy: 0.9596 - val_loss: 0.6494 - val_accuracy: 0.7927\n","Epoch 10/10\n","18/18 [==============================] - 2s 120ms/step - loss: 0.1104 - accuracy: 0.9664 - val_loss: 0.6492 - val_accuracy: 0.7909\n"]}],"source":["history = model_bilstm.fit(train['text'], train['label'], validation_data=(test['text'], test['label']), epochs=10, batch_size=128)"]},{"cell_type":"markdown","id":"ecd7f0f5-b43a-408d-a04d-9e0b688d8470","metadata":{"pycharm":{"name":"#%% md\n"},"id":"ecd7f0f5-b43a-408d-a04d-9e0b688d8470"},"source":["Далее мы попробуем реализовать и добавить модуль внимания. В данном модуле мы будем учитывать принимать данные с предыдущего рекуррентного слоя, оценивать каждый из векторов с помощью полносвязного слоя, а затем складывать их с получившимися весами.  \n","\n","Давайте реализуем данный модуль самостоятельно."]},{"cell_type":"code","execution_count":null,"id":"563c73e0-c662-439f-82d4-9468d7f642b1","metadata":{"tags":[],"pycharm":{"name":"#%%\n"},"id":"563c73e0-c662-439f-82d4-9468d7f642b1"},"outputs":[],"source":["class Attention(Layer):\n","    \"\"\"\n","    Реализуем модуль внимания самостоятельно, используя возможности фреймворка TensorFlow. \n","    В данном случае модуль будет принимать трехмерный тензор, осуществлять механизм внимания и\n","    возвращать суммированный двумерный вектор с учетом внимания.\n","    \"\"\"\n","    \n","    def __init__(self, return_sequences=True):\n","        \"\"\"\n","        На вход данного слоя следует подавать 3-хмерный тензор: [batch, time, data],\n","        поэтому все предыдущие LSTM слои должны быть инициализированы с \"return_sequences=True\"\n","        \n","        Если вы хотите использовать LSTM слои после данного слоя - инициализируйте этот слой с `return_sequences=True`,\n","        тогда выходом будет [batch, time, data]\n","        \n","        В противном случае данные с каждого шага времени будут суммированы и размерность выхода будет следующая: [batch, time]. \n","        В таком случае следующем слоем должен быть слой, ожидающий двумерный вход (например, Dense)\n","        \"\"\"\n","        \n","        self.return_sequences = return_sequences\n","        super().__init__()\n","        \n","    def build(self, input_shape):\n","        # Веса слоя\n","        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1), initializer=\"normal\")\n","        super().build(input_shape)\n","        \n","    def call(self, x):\n","        \n","        # Реализуем обычный полносвязный слой, умножив входящий тензор на веса, после чего применим нелинейную активацию\n","        e = K.tanh(K.dot(x, self.W))\n","        \n","        # Далее посчитаем softmax от полученных векторов по размерности time, т.о. присвоив важность каждому из векторов data\n","        a = K.softmax(e, axis=1)\n","        \n","        # Далее возьмем входные данные и домножим на получившиеся веса - каждый из векторов data будет домножен на соответствующий вес внимания\n","        output = x*a\n","        \n","        # Если в дальнейшем необходимо сохранить оригинальные данные, возвращаем трехмерный вектор\n","        if self.return_sequences:\n","            return output\n","        \n","        # Иначе - суммируем вектор по оси time, получая двумерный вектор. \n","        # Таким образом, мы сложили все векторы data по оси time, домножив их на веса от механизма внимания.\n","        return K.sum(output, axis=1)"]},{"cell_type":"markdown","id":"1179dfb4-417d-4c6e-976e-4a90ca0cb2da","metadata":{"pycharm":{"name":"#%% md\n"},"id":"1179dfb4-417d-4c6e-976e-4a90ca0cb2da"},"source":["Создадим модель, аналогичную предыдущей, в которую добавим слои внимания. Учтите, что теперь оба LSTM слоя инициализированы с `return_sequence` для возвращения трехмерного вектора $[batch, timestep, data]$, а последний слой внимания инициалирован без данного параметра для корректной передачи данных далее в полносвязный слой."]},{"cell_type":"code","execution_count":null,"id":"bc58b375-8fb8-4693-b6fd-b51634374c10","metadata":{"pycharm":{"name":"#%%\n"},"id":"bc58b375-8fb8-4693-b6fd-b51634374c10"},"outputs":[],"source":["model_att = tf.keras.Sequential([\n","    Input(shape=(1,), dtype=tf.string),\n","    encoder,\n","    Embedding(input_dim=len(encoder.get_vocabulary()), output_dim=100),\n","    Bidirectional(LSTM(32, return_sequences=True)),\n","    Attention(return_sequences=True),\n","    Bidirectional(LSTM(32, return_sequences=True)),\n","    Attention(return_sequences=False),\n","    Dense(32, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","model_att.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"markdown","id":"968ea773-9064-4922-bcbd-78be33323a8c","metadata":{"pycharm":{"name":"#%% md\n"},"id":"968ea773-9064-4922-bcbd-78be33323a8c"},"source":["Натренируем модель с механизмом внимания."]},{"cell_type":"code","execution_count":null,"id":"3bd58e64-fd41-43ac-8355-b87fba853146","metadata":{"pycharm":{"name":"#%%\n"},"id":"3bd58e64-fd41-43ac-8355-b87fba853146","outputId":"5469db6d-6fd0-48ff-e1cc-6ea077175031"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["2022-09-23 17:16:31.829242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:16:32.218102: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:16:32.250071: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:16:32.595933: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:16:32.606394: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:16:33.030687: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:16:33.048797: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:16:33.309922: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:16:33.328485: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["18/18 [==============================] - ETA: 0s - loss: 0.6784 - accuracy: 0.6470"]},{"name":"stderr","output_type":"stream","text":["2022-09-23 17:16:41.107126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:16:41.254334: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:16:41.262632: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:16:41.408143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n","2022-09-23 17:16:41.415478: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["18/18 [==============================] - 13s 511ms/step - loss: 0.6784 - accuracy: 0.6470 - val_loss: 0.6376 - val_accuracy: 0.7073\n","Epoch 2/10\n","18/18 [==============================] - 3s 177ms/step - loss: 0.6438 - accuracy: 0.6670 - val_loss: 0.6151 - val_accuracy: 0.7073\n","Epoch 3/10\n","18/18 [==============================] - 2s 139ms/step - loss: 0.6403 - accuracy: 0.6670 - val_loss: 0.6105 - val_accuracy: 0.7073\n","Epoch 4/10\n","18/18 [==============================] - 3s 165ms/step - loss: 0.6286 - accuracy: 0.6670 - val_loss: 0.5679 - val_accuracy: 0.7073\n","Epoch 5/10\n","18/18 [==============================] - 3s 143ms/step - loss: 0.5482 - accuracy: 0.6692 - val_loss: 0.4646 - val_accuracy: 0.7818\n","Epoch 6/10\n","18/18 [==============================] - 3s 145ms/step - loss: 0.4557 - accuracy: 0.8124 - val_loss: 0.4567 - val_accuracy: 0.8182\n","Epoch 7/10\n","18/18 [==============================] - 3s 159ms/step - loss: 0.3915 - accuracy: 0.8569 - val_loss: 0.4582 - val_accuracy: 0.8182\n","Epoch 8/10\n","18/18 [==============================] - 3s 173ms/step - loss: 0.3322 - accuracy: 0.8814 - val_loss: 0.4653 - val_accuracy: 0.8182\n","Epoch 9/10\n","18/18 [==============================] - 3s 142ms/step - loss: 0.2980 - accuracy: 0.8891 - val_loss: 0.4596 - val_accuracy: 0.8018\n","Epoch 10/10\n","18/18 [==============================] - 3s 147ms/step - loss: 0.2611 - accuracy: 0.9050 - val_loss: 0.5306 - val_accuracy: 0.8200\n"]}],"source":["history = model_att.fit(train['text'], train['label'], validation_data=(test['text'], test['label']), epochs=10, batch_size=128)"]},{"cell_type":"markdown","id":"7de79a94-c337-4b6b-8515-b8742ac0d61c","metadata":{"pycharm":{"name":"#%% md\n"},"id":"7de79a94-c337-4b6b-8515-b8742ac0d61c"},"source":["Отметьте, каким стало значение функции потерь и точности на валидационной выборке.  \n","\n","Отличаются ли они? Насколько сильно? Учитывайте, что данный набор данных достаточно прост для этой задачи. Каким образом это может влиять на эффективность механизма внимания?\n","\n","Сможете ли вы изменить сеть или данные так, чтобы влияние механизма внимания стало более заметно?\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}