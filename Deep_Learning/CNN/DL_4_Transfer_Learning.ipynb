{"cells":[{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"c8WPgKhvJtj2"},"source":["# Transfer learning и fine-tuning\n","\n","Данный блокнот основан на материалах документации фреймворка TensorFlow, опубликованных коллективом TensorFlow Authors: https://www.tensorflow.org/guide/keras/transfer_learning."]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"id":"AlJpiX8QJtj4","outputId":"9a447215-9b9a-49c3-8aac-840cca63595d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\u001b[0m\r\n","\u001b[31mERROR: No matching distribution found for tensorflow\u001b[0m\r\n"]}],"source":["!pip install tensorflow tensorflow_datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9a7e9b92f963","tags":[],"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"markdown","metadata":{"tags":[],"pycharm":{"name":"#%% md\n"},"id":"r0SAf-ZmJtj5"},"source":["# Как осуществить transfer learning?\n","Процесс transfer learning'а заключается в следующем:\n","1. Возьмем «backbone» (или другие слои, если вы считаете это необходимым) от модели, натренированной на схожей задаче. Такой процесс иноглда называют «отрыванием головы».\n","2. «Заморозим» их, то есть сделаем их необучаемыми.\n","3. Добавим несколько новых обучаемых слоев («голову»), которые будут учиться преобразовывать признаки с уже обученных предыдущих слоев для принятия решения в новой задаче\n","4. Обучим всю новую сеть (в которой backbone заморожен) на новых данных\n","\n","# Fine-tuning\n","После того, как мы обучим новую голову с перенесенным backbone'ом, достаточно часто применяют процесс fine-tuning'а. На предыдущих шагах мы никак не изменяли backbone, а значит в нем присутствуют некоторые признаки, которые либо бесполезны, либо мешают новой задаче. Идея fine-tuning заключается в том, что после того, как мы научили новую голову работать со старым backbone'ом, мы можем «разморозить» всю сеть (реже -- только часть backbone'а) и пообучать ее несколько эпох с очень низким learning rate'ом. Это поможет подстроить старые слои к решению новой задачи, перестроить или адаптировать некоторые фильтры, и сделать процесс принятия решения более цельным. Низкий learning rate и факт предобучения головы со старым backbone'ом позволяет не развалить всю сеть, а аккуратно подстроить ее под нужную область."]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"tbHIX2aDJtj5"},"source":["# Заморозка весов\n","Слои нейронной сети состоят из весов, большая часть из которых является тренируемыми (хотя некоторые - нет, так как нужны для определенных операций).\n","Давайте посмотрим на веса простого полносвязного слоя:"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"id":"EKW7proXJtj6","outputId":"a52fb8aa-f50a-46df-ca1d-274574190ea2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Metal device set to: Apple M1 Pro\n","weights: 2\n","trainable_weights: 2\n","non_trainable_weights: 0\n"]},{"name":"stderr","output_type":"stream","text":["2022-07-23 16:39:59.128614: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n","2022-07-23 16:39:59.129245: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"]}],"source":["layer = keras.layers.Dense(3)\n","layer.build((None, 4))  # Инициализируем веса\n","\n","print(\"weights:\", len(layer.weights))\n","print(\"trainable_weights:\", len(layer.trainable_weights))\n","print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"jfriMgp5Jtj6"},"source":["Вы можете изменить атрибут trainable у слоя, чтобы сделать веса нетренируемыми. В процессе тренировки данные веса не будут изменяться."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51bbc5d12742","tags":[],"pycharm":{"name":"#%%\n"},"outputId":"d3bcf0ef-e6e7-4e48-efcd-85965cad9a56"},"outputs":[{"name":"stdout","output_type":"stream","text":["weights: 2\n","trainable_weights: 0\n","non_trainable_weights: 2\n"]}],"source":["layer = keras.layers.Dense(3)\n","layer.build((None, 4))  # Инициализируем веса\n","layer.trainable = False  # Заморозим слой\n","\n","print(\"weights:\", len(layer.weights))\n","print(\"trainable_weights:\", len(layer.trainable_weights))\n","print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"6hcrif4-Jtj7"},"source":["Кроме того, когда вы устанавливаете флаг заморозки на модель, он устанавливается на все объекты и подобъекты данной модели."]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"id":"FvKVinSeJtj7"},"outputs":[],"source":["inner_model = keras.Sequential(\n","    [\n","        keras.layers.Dense(3, activation=\"relu\"),\n","        keras.layers.Dense(3, activation=\"relu\"),\n","    ]\n",")\n","\n","model = keras.Sequential(\n","    [keras.Input(shape=(3,)), inner_model, keras.layers.Dense(3, activation=\"sigmoid\"),]\n",")\n","\n","model.trainable = False  # Freeze the outer model\n","\n","assert inner_model.trainable == False  # Все веса модели заморожены\n","assert inner_model.layers[0].trainable == False  # и внутренней модели тоже"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"VYnsRmsiJtj8"},"source":["Давайте скопируем старые веса, попробуем обучить модель чему-нибудь и сравним веса после обучения со старыми."]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"id":"uNGUVJYMJtj8","outputId":"6d3ac2b6-6b93-47ba-d935-516043d06521"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n"]},{"name":"stderr","output_type":"stream","text":["2022-07-23 16:40:21.980533: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n","2022-07-23 16:40:22.113494: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 388ms/step - loss: 0.0750\n","Epoch 2/3\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0750\n","Epoch 3/3\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0750\n","Веса слоев 0 равны: True\n","Веса слоев 1 равны: True\n","Веса слоев 2 равны: True\n","Веса слоев 3 равны: True\n","Веса слоев 4 равны: True\n","Веса слоев 5 равны: True\n"]}],"source":["old_weights = model.get_weights()\n","\n","model.compile(optimizer=\"adam\", loss=\"mse\")\n","model.fit(np.random.random((2, 3)), np.random.random((2, 3)), epochs=3)\n","\n","for i, (old_w, new_w) in enumerate(zip(old_weights, model.get_weights())):\n","    print(f\"Веса слоев {i} равны: {np.allclose(old_w, new_w)}\")"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"UP0IHsUPJtj8"},"source":["Как можно заметить, веса модели не изменились в процессе обучения."]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"k4_vRymfJtj9"},"source":["##  Применение tranfer learning'а в фреймворке Keras\n","\n","В фреймворке Keras есть встроенная возможность использовать пре-тренированные модели.  \n","\n","Для этого в модуле `keras.applications` представлены классы для инициализации различных моделей. При инициализации нам интересные следующие параметры:\n","- weights: источник весов. None для случайной инициализации, imagenet для pre-trained модели на наборе данных ImageNet, или путь до весов данной модели\n","- input_shape или input_tensor: форма входного тензора или ссылка на него\n","- include_top: включать ли 'голову' (полносвязные слои)\n","\n","Пример инициализации сети EfficientNet для transfer learning'а:\n","```python\n","base_model = keras.applications.EfficientNetB0(\n","    weights='imagenet',\n","    input_shape=(150, 150, 3),\n","    include_top=False\n",") \n","```\n","\n","Далее заморозим текущую модель:\n","\n","```python\n","base_model.trainable = False\n","```\n","\n","После чего создадим подходящие входной тензор и 'голову' модели. Заметьте, что в данном случае мы пользуемся \"функциональным\" стилем создания слоев \n","\n","```python\n","inputs = keras.Input(shape=(150, 150, 3))\n","x = base_model(inputs, training=False)\n","\n","# Вместо Flatten() будем использовать GlobalAveragePooling. О разнице можно прочитать, например, здесь: https://stackoverflow.com/questions/49295311/what-is-the-difference-between-flatten-and-globalaveragepooling2d-in-keras\n","x = keras.layers.GlobalAveragePooling2D()(x)\n","\n","# Голова модели - несколько (в данном случае - один) полносвязных слоев\n","outputs = keras.layers.Dense(1, activation='softmax')(x)\n","\n","# Создадим объект модели, указав входные и выходные тензоры\n","model = keras.Model(inputs, outputs)\n","```\n","\n","После чего скомпилируем модель с необходимыми параметрами и вызовем метод `fit()` на нужным нам данных.\n","\n","```python\n","model.compile(optimizer=keras.optimizers.Adam(),\n","              loss=keras.losses.BinaryCrossentropy(),\n","              metrics=[keras.metrics.BinaryAccuracy()])\n","model.fit(new_dataset, epochs=20, callbacks=..., validation_data=...)\n","```"]},{"cell_type":"markdown","metadata":{"id":"736c99aea690","tags":[],"pycharm":{"name":"#%% md\n"}},"source":["## Реализация fine-tuning в фреймворке Keras\n","\n","После тренировки модели и достижения достаточной точности, можно разморозить слои и провести процесс fine-tuning'а модели.\n","Для этого флагу `trainable` всей модели снова присваивается значение `True` и, \n","как мы указывали ранее, производится обучение с небольшим значением learning rate.\n","\n","```python\n","base_model.trainable = True\n","\n","# После изменения статуса trainable необходима рекомпиляция модели\n","model.compile(optimizer=keras.optimizers.Adam(1e-5),  # Не забываем про низкий learning rate\n","              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=[keras.metrics.BinaryAccuracy()])\n","\n","model.fit(new_dataset, epochs=10, callbacks=..., validation_data=...)\n","```"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"_NsfFClBJtj9"},"source":["## Пример реализации\n","\n","Давайте в качестве примера выполним все вышеописанное на наборе данных \"tf_flowers\". Как обычно, скачаем набор данных и импорируем."]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"id":"WbG4e0TTJtj9","outputId":"ab0285aa-cc3c-4f3c-c457-f4ee53195220","colab":{"referenced_widgets":["799ac91197df4f7d85a8f5ee4dddb44b"]}},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-07-23 16:40:48.154122: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1mDownloading and preparing dataset 218.21 MiB (download: 218.21 MiB, generated: 221.83 MiB, total: 440.05 MiB) to ~/tensorflow_datasets/tf_flowers/3.0.1...\u001b[0m\n"]},{"data":{"text/plain":"Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"799ac91197df4f7d85a8f5ee4dddb44b"}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\u001b[1mDataset tf_flowers downloaded and prepared to ~/tensorflow_datasets/tf_flowers/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"]}],"source":["import tensorflow_datasets as tfds\n","\n","(train_ds, test_ds), ds_info = tfds.load(\n","    \"tf_flowers\",\n","    split=[\"train[:30%]\", \"train[30%:40%]\"],     # Возьмем набор данных поменьше\n","    as_supervised=True,\n","    with_info=True\n",")\n","\n","# Задача мультиклассовой классификации\n","NUM_CLASSES = ds_info.features['label'].num_classes"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"xpQ18HnvJtj-"},"source":["Т.к. изображения представлены разного размера. Приведем их к единому размеру, который используется сетью EfficientNetB0 (224x224) и соберем в батчи по 32 изображения."]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"id":"zKGE_nV6Jtj-"},"outputs":[],"source":["SIZE = (224, 224)\n","SHAPE = (*SIZE, 3)\n","BATCH_SIZE = 32\n","\n","train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, SIZE), y))\n","test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, SIZE), y))"]},{"cell_type":"markdown","metadata":{"pycharm":{"name":"#%% md\n"},"id":"98qwor8JJtj-"},"source":["Кроме того, стандартным способом преобразуем метки классов в one-hot вектора"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"id":"KRrxy6FFJtj-"},"outputs":[],"source":["def make_one_hot(x, y):\n","    return x, tf.one_hot(y, depth=NUM_CLASSES)\n","\n","train_ds = train_ds.map(make_one_hot).batch(BATCH_SIZE)\n","test_ds = test_ds.map(make_one_hot).batch(BATCH_SIZE)"]},{"cell_type":"code","execution_count":null,"metadata":{"pycharm":{"name":"#%%\n"},"id":"U3r-2B6aJtj_","outputId":"8748f28e-3558-48ee-8dbf-e8c4518766b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n","16705208/16705208 [==============================] - 4s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n","                                                                 \n"," global_average_pooling2d (G  (None, 1280)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dropout (Dropout)           (None, 1280)              0         \n","                                                                 \n"," dense_5 (Dense)             (None, 128)               163968    \n","                                                                 \n"," dense_6 (Dense)             (None, 5)                 645       \n","                                                                 \n","=================================================================\n","Total params: 4,214,184\n","Trainable params: 164,613\n","Non-trainable params: 4,049,571\n","_________________________________________________________________\n"]}],"source":["base_model = keras.applications.EfficientNetB0(\n","    weights='imagenet',\n","    input_shape=SHAPE,\n","    include_top=False\n",") \n","\n","# Заморозим веса\n","base_model.trainable = False\n","\n","# Создадим входной тензор\n","inputs = keras.Input(shape=SHAPE)\n","\n","x = base_model(inputs, training=False)\n","x = keras.layers.GlobalAveragePooling2D()(x)\n","x = keras.layers.Dropout(0.2)(x)\n","x = keras.layers.Dense(128)(x)\n","outputs = keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n","model = keras.Model(inputs, outputs)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"2e8237de81e8","pycharm":{"name":"#%% md\n"}},"source":["## Train the top layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9137b8daedad","tags":[],"pycharm":{"name":"#%%\n"}},"outputs":[],"source":["model.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    loss=keras.losses.CategoricalCrossentropy(),\n","    metrics=[keras.metrics.CategoricalAccuracy()],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[],"pycharm":{"name":"#%%\n"},"id":"SZ23sZMKJtj_","outputId":"b4ab6015-fee5-42c8-9fa8-7f0a34008dd9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n"]},{"name":"stderr","output_type":"stream","text":["2022-07-23 16:41:50.046754: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["35/35 [==============================] - ETA: 0s - loss: 0.5615 - categorical_accuracy: 0.7856"]},{"name":"stderr","output_type":"stream","text":["2022-07-23 16:41:58.559930: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["35/35 [==============================] - 13s 190ms/step - loss: 0.5615 - categorical_accuracy: 0.7856 - val_loss: 0.3538 - val_categorical_accuracy: 0.8692\n","Epoch 2/3\n","35/35 [==============================] - 4s 121ms/step - loss: 0.1457 - categorical_accuracy: 0.9591 - val_loss: 0.3279 - val_categorical_accuracy: 0.8747\n","Epoch 3/3\n","35/35 [==============================] - 4s 116ms/step - loss: 0.0742 - categorical_accuracy: 0.9882 - val_loss: 0.3075 - val_categorical_accuracy: 0.8856\n"]},{"data":{"text/plain":"<keras.callbacks.History at 0x174ba0760>"},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Количество эпох выставлено для быстрого обучения на слабых компьютерах\n","# Если у вас есть графический ускоритель - можно поставить вплоть до 20\n","epochs = 3  \n","model.fit(train_ds, epochs=epochs, validation_data=test_ds)"]},{"cell_type":"markdown","metadata":{"id":"aa51d4562fa7","pycharm":{"name":"#%% md\n"}},"source":["## Fine-tuning\n","\n","После обучения мы можем выполнить несколько эпох fine-tuning'а.\n","\n","Для этого разморозим веса, перекомпилируем модель (веса не сбрасываются при перекомпиляции) \n","и обучим модель в течение нескольких эпох с небольшим learning rate."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3cc299505b72","tags":[],"pycharm":{"name":"#%%\n"},"outputId":"eea41ec8-5303-4ac4-b924-4a4bbaff8eaa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n","                                                                 \n"," global_average_pooling2d (G  (None, 1280)             0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," dropout (Dropout)           (None, 1280)              0         \n","                                                                 \n"," dense_5 (Dense)             (None, 128)               163968    \n","                                                                 \n"," dense_6 (Dense)             (None, 5)                 645       \n","                                                                 \n","=================================================================\n","Total params: 4,214,184\n","Trainable params: 4,172,161\n","Non-trainable params: 42,023\n","_________________________________________________________________\n"]},{"name":"stderr","output_type":"stream","text":["2022-07-23 16:42:12.031283: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["35/35 [==============================] - ETA: 0s - loss: 0.0359 - categorical_accuracy: 0.9973"]},{"name":"stderr","output_type":"stream","text":["2022-07-23 16:42:35.086472: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["35/35 [==============================] - 29s 524ms/step - loss: 0.0359 - categorical_accuracy: 0.9973 - val_loss: 0.3152 - val_categorical_accuracy: 0.8883\n"]},{"data":{"text/plain":"<keras.callbacks.History at 0x2ccac8580>"},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["base_model.trainable = True\n","model.summary()\n","\n","model.compile(\n","    optimizer=keras.optimizers.Adam(1e-5),\n","    loss=keras.losses.CategoricalCrossentropy(),\n","    metrics=[keras.metrics.CategoricalAccuracy()],\n",")\n","\n","epochs = 1\n","model.fit(train_ds, epochs=epochs, validation_data=test_ds)"]},{"cell_type":"markdown","source":["Мы с вами провели процесс transfer learning'а - переобучения существующей модели к нашей текущей задаче. С помощью данного процесса вы можете использовать большие предобученные модели (в идеале - на схожих датасетах) для ваших задач с небольшими ресурсами для дообучения.\n","\n","Желаем успехов в дальнейшем обучении!\n"],"metadata":{"collapsed":false,"pycharm":{"name":"#%% md\n"},"id":"Ti6TJ5XWJtkA"}}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3 (ipykernel)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"}},"nbformat":4,"nbformat_minor":0}